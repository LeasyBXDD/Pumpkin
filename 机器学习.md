# 机器学习（一周速通）

# 第一章：绪论

## 一、机器学习的定义

机器学习是人工智能的核心研究领域之一，其研究是为了让计算机系统具有人的学习能力以便实现人工智能。

目前被广泛采用的机器学习的定义是 **“利用经验来改善计算机系统自身的性能”**。由于“经验”在计算机系统中主要是以数据的形式存在的，因此机器学习需要运用机器学习技术对数据进行分析，这就使得它主键成为智能数据分析技术的创新源之一，并且为此而收到越来越多的关注。

机器学习的教材和课程主要讲解各种不同的机器学习技术。比如：线性学习、支持向量机学习、神经网络学习、决策树学习、贝叶斯学习、最近邻学习等等。

## 二、与数据挖掘的区别和联系

当人们讨论机器学习的时候，经常会想到另一种智能数据分析技术：**数据挖掘**。

所谓 **数据挖掘** 就是：**”识别出巨量数据中有效的、新颖的、潜在有用的、最终可理解的模式的非平凡过程“**。

顾名思义，**数据挖掘就是试图从海量数据中找出有用的知识**。

数据挖掘的教材和课程主要讲解各种不同的数据挖掘任务。比如：分类、回归、聚类、关联分析、异常分析、演变分析等等。

数据挖掘可以视为机器学习和数据库的交叉，它主要利用机器学习界提供的技术来分析海量数据，利用数据库界提供的技术来管理海量数据。

二者既有区别又有联系，整体来说，机器学习偏理论，数据挖掘偏应用。

![image-20230718104100602](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230718104100602.png)

## 三、授课思路

本课程的授课思路：以数据挖掘中的分类任务为例，首先讲解分类模型的评估，然后讲解各种不同的机器学习技术。

现在我们来看看分类的定义，分类就是构建一个分类模型，即分类器，然后通过分类器将数据对象映射到某个给定的类别中的过程。分类过程可以分为两步：

1. 第一步使用已知类标记的训练数据集学习分类模型，这一步成为分类器的训练阶段。
2. 第二步应用分类模型对未知类标记的对象进行分类。这一步称为分类器的工作阶段。实际上，在工作之前还应该对学到的饿模型进行模型测试评估（这一步称为分类器的测试阶段），如果模型的性能可以接受，才可以用它来对未知类标记的对象进行分类。

分类是一个三步走的过程：训练 -> 测试 -> 工作

![image-20230718143013753](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230718143013753.png)

多示例多标记学习，机器学习及其应用

# 第二章、模型评估

## 一、评估方法

在学习得到的模型投放使用之前，通常需要对其进行性能评估。为此需要使用一个**测试集**来测试模型对新样本的**泛化能力**，然后以测试集上的**测试误差**作为泛化误差的近似。

我们假设测试集是从样本真实分布中独立采样获得，所以测试集要和训练集中的样本尽量互斥。

给定一个已知的数据集，将数据集拆分成训练集S和测试集T，通常的做法包括 **留出法、交叉验证法、自助法**

### 1.1 留出法

直接将数据集划分为两个互斥集合

训练/测试集划分要尽可能保持数据分布的一致性

一般若干次随机划分、重复实验取平均值

训练/测试样本比例通常为2:1~4:1

### 1.2 交叉验证法

将数据集分层采样划分为k个大小相似的互斥子集，每次用k-1个子集的并集作为训练集，余下的子集作为测试集，最终返回k个测试结果的均值，k最常用的取值是10。

![image-20230718144740668](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230718144740668.png)

与留出法类似，将数据集D划分为k个子集同样存在多种划分方式，为了减小因样本划分不同而引入的差别，k折交叉验证通常随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值，例如常见的“10次10折交叉验证”。

假设数据集D包含m个样本，若令k=m，则得到留一法：

1. 不受随机样本划分方式的影响
2. 结果往往比较准确
3. 当数据集比较大的时候，计算开销难以忍受

### 1.3 自助法

数据集较小时

***以自助采样法为基础，对数据集D有放回采样m次得到训练集D'，D\D'用作测试集。***

1. 实际模型与预期模型都使用m个训练样本。
2. 约有1/3的样本没有在训练集中出现，用作测试集。
3. 从初始数据集中产生多个不同的训练集，对集成学习有很大的好处。
4. 自助法在数据集较小、难以有效划分训练/测试集时很有用；由于改变了数据集分布可能引入估计偏差，在数据量足够时，留出法和交叉验证发更常用。

## 二、评估指标

要评估模型的好坏有评估方法还不行，还得确定评估指标。

所谓评估指标就是衡量模型泛化能力好坏的评估标准，反映了任务需求；使用不同的评估指标往往会导致不同的评估结果。

在分类预测任务中，给定测试样例集，评估分类模型的性能就是把对每一个待测样本的分类及过和它的真实标记比较。

因此，准确率和错误率时最常用的两种评估指标：

**准确率**就是分对样本占测试样本总数的比例；

**错误率**就是分错样本占测试样本总数的比例。

由于准确率和错误率将每个类看的同等重要，因此不适合用来分析类不平衡数据集。

在类不平衡数据集中，正确分类稀有类比正确分类多数类更有意义。此时查准率和查全率比准确率和错误率更加适合。对于二分类问题，稀有类样本通常记为正例，而多数类样本记为负例。

统计真实标记和预测结果的组合可以得到如下所示的混淆矩阵。

| 真实情况 | 正例         | 负例         |
| -------- | ------------ | ------------ |
| 正例     | TP（真正例） | FN（假负例） |
| 负例     | FP（假正例） | TN（真负例） |

**查准率（P）**就是被分为正类的样本中实际为正类的样本比例：

P=TP/(TP+FP)

**查全率（R）**就是实际分为正类的样本中被分为正类的样本比例：

R=TR/(TP+FN)

可见，查准率是被分类器分为正类的样本中实际为正类的比例；而查全率是被分类器正确分类为正类的比例。

二者通常是矛盾的。查准率高的时候，查全率往往偏低；反之亦然。

为综合考量查准率和查全率，他们的调和均值**F1度量**被提出：
$$
F1 = 2*p*R/P+R=2*TP/样例总数+TP-TN
$$
比F1更一般的形式Fb，
$$
Fb=(1+b^2)*P*R/(b^2*P)+R
$$
b=1：标准的F1

b>1：偏重查全率

b<1：偏重查准率

很多分类器可以为测试样例产生一个概率预测，因此可以根据预测的概率将测试样例进行排序，把最可能是正例的排在最前面，把最不可能是正例的排在最后面。这样，分类过程就相当于在这个排序中以某个“截断点”将样本分为两部分，前一部分判为正例，后一部分判为反例。在不同的应用任务下，用户可以根据不同的任务需求来选择不同的截断点。因此，排序本身的质量好坏体现了分类器在不同任务下的泛化性能。

贝叶斯分类器，根据概率排序，正例、反例，根据不同的任务需求

受试者工作特征曲线 ROC （Receiver Operating Characteristics）

根据分类器的预测结果对样例排序，并作为正例进行预测，每次计算出当前分类器的“真正率”和“假正率”，然后分别以它们为纵轴和横轴绘图，就可以得到ROC曲线。

**真正率（TPR）**就是被分为正类的正样本比例：

TPR=TP/(TP+FN)

**假正率（FPR）**就是被分为正类的负样本比例：

FPR=FP/(FP+TN)

![image-20230718201431930](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230718201431930.png)

![image-20230719094935344](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719094935344.png)

若某个分类器的ROC曲线被另一个分类器的曲线 **包住**，则后者性能优于前者；否则如果曲线交叉，可以根据ROC曲线下的面积的大小进行比较，即AUC（Area Under ROC Curve）。

AUC的计算：
$$
AUC=
$$
![image-20230719095423477](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719095423477.png)

其中，n0和n1分别表示反例和正例的个数，ri分别为第i个反例（-）在整个测试样例中的排序。

AUC度量了分类器预测样本排序的性能。

对于刚才的例子，具体如表（1）所示：

![image-20230719095706646](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719095706646.png)

反例、正例

条件似然性CLL（Conditional Log Likelihood）的计算

给定分类器G和一个测试样本集T={x1, x2, ... , xi ... , xt}

假设每一个测试样本xi的真实类标记是yi

那么分类器G预测测试样本集T的CLL定义如下：

![image-20230719095941808](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719095941808.png)

CLL度量了分类器预测样本类成员概率的性能。

## 三、比较检验

有了实验评估方法和评估指标，看似可以对分类器的性能进行评估比较了：先使用某种实验评估方法测得分类器的某个评估指标结果，然后对这些结果进行比较。但怎么来做这个 **比较** 呢？是直接比较不同分类器的评估指标结果吗？

使用某些评估指标结果，然后对这些结果进行比较

关于性能的比较

1. 测试性能不等于泛化性能
2. 测试性能会随着测试集的变化而变化
3. 很多机器学习算法本身也有一定的随机性

直接选取相应评估方法在相应度量下比大小的方法不可取。

假设检验为分类器的性能比较提供了重要依据，基于其结果，我们可以推断出，若在测试集上观察到分类器A比B好，则A的泛化性能是否可以在统计意义上优于B，以及这个结论的把握有多大。

下面我们将介绍几种常用的机器学习性能比较方法来对不同的分类器的性能进行比较。

测试集上

统计意义上

常用的比较方法

成对双边t检验

对两个分类器A和B，若k折交叉验证得到的测试错误率分别为![image-20230719100802777](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719100802777.png)，可用 **成对t检验** 进行比较检验。若两个分类器的性能相同，则他们使用相同的训练/测试集得到的测试错误率应相同，即![image-20230719100943857](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719100943857.png)

具体来说，对k折交叉验证产生的k对测试错误率：先对每对结果求差，![image-20230719101034122](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719101034122.png)；然后根据差值![image-20230719101056302](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719101056302.png)来对 **分类器A与B性能相同** 这个假设做t检验，计算出差值的均值![image-20230719101140344](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719101140344.png)和方差![image-20230719101154047](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719101154047.png)，以及t统计量：

![image-20230719101220803](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719101220803.png)

因为计算得到的t统计量服从自由度为k-1的t分布，如果t值小于双边t检验在显著度alpha下的临界值，则人为这两个分类器的性能没有显著差别；否则可以人为这两个分类器的性能有显著差别，且平均错误率较小的那个分类器的性能较优。

在不同自由度v和显著度alpha下的临界值可以通过查找t分布的临界值表得到。

![image-20230719103122627](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719103122627.png)

测试错误率

求差

Friedman检验与Nemenyi后续检验

**成对双边t检验**是一个在数据集上比较**两个分类器**的性能，而在很多时候，我们需要在**一组数据集**上标记**多个分类器**的性能，这就需要使用基于排序的**Friedman检验**。

假定我们要在n个数据集上比较k个算法，首先使用留出法或者交叉验证法得到每个算法在每个数据集上的测试结果，然后在每个数据集上根据性能好坏排序，并赋序值1，2，……；若算法性能相同则平分序值，继而得到每个算法在所有数据集上的平均序值。

![image-20230719103654044](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719103654044.png)

![image-20230719103835118](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719103835118.png)

![image-20230719104133660](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719104133660.png)

![image-20230719104149867](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719104149867.png)

![image-20230719104203558](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719104203558.png)

留出法 交叉验证法

测试结果 序值

Tukey

计算平均序值差别的临界阈值

平均序值越小越好

例题

假设用D1、D2、D3、D4四个数据集对A、B、C三个算法进行比较

Friedman检验图

若两个算法没有交叠，则说明有显著差别

# 第三章、线性学习

## 一、线性回归

提及线性学习，我们首先会想到线性回归。回归跟分类的区别在于要预测的目标函数是连续值。

给定由m个属性描述的样本![image-20230719110635737](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719110635737.png)，其中xi是x在第i个属性上的取值，线性回归（linear regression)试图学得一个通过属性值的线性组合来进行预测的函数。

![image-20230719110813850](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719110813850.png)

一般用向量的形式写成：

![image-20230719110833019](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719110833019.png)

其中![image-20230719110844697](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719110844697.png)。

给定训练数![image-20230719110914591](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719110914591.png)

可以用最小二乘法（least square method）对w和b进行估计。

下面以一元线性回归为例，来详细讲解w和b的最小二乘法估计。

![image-20230719111041593](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719111041593.png)

最小二乘法就是基于预测值和真实值的均方差最小化的方法来估计参数w和b：

![image-20230719111124748](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719111124748.png)

![image-20230719111136220](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719111136220.png)

![image-20230719111146697](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719111146697.png)

只要学到w和b，模型就可以确定；对于任意的测试样例x，只要输入它的属性值，就可以输出它的预测值。

线性回归假定输入空间到输出空间的函数映射成线性关系，但是现实应用中，很多问题都是非线性的，为拓展其应用场景，我们可以将线性回归的预测值做一个非线性的函数变化取毕竟真实值，这样的到的模型统称更为广义线性回归（generalized linear regression）

![image-20230719111437264](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719111437264.png)

理论上，联系函数g(·)可以是任意函数，比如当g(·)被指定为指数函数时，得到的回归模型被称为对数线性回归。

之所以叫对数线性回归，是因为它将真实值的对数作为线性回归逼近的目标，即：

![image-20230719111646101](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719111646101.png)

线性回归假定输入控件到输出空间 为线性关系

广义线性回归

联系函数

对数线性回归

将真实值的对数作为线性回归逼近的目标

分类任务

二分类任务

输出标记 只有0和1两个值

线性回归产生的预测值是连续值

单位阶跃函数

## 三、逻辑斯蒂回归

前面的内容都是在讲解如何利用线性模型进行回归学习，完成回归任务。但如果我们要做的时分类任务该怎么办？

为了简化，我们先考虑二分类任务，其输出标记y属于0和1，但线性回归模型产生的预测值![image-20230719111859635](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719111859635.png)是实值，因此，我们需要将实值z转换为0/1值。最容易想到的联系函数g(·)当然是单位阶跃函数：

![image-20230719112006733](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719112006733.png)

但单位阶跃函数不连续，因此不能直接用作联系函数g(·)。于是我们希望找到**能在一定程度上近似单位阶跃函数的替代函数，并希望它在临界点连续且单调可微**。逻辑斯蒂正式这样一个常用的替代函数。

![image-20230719112300323](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719112300323.png)

逻辑斯蒂函数形似s，是Sigmoid函数的典型代表，他将z值转化为一个接近0或1的y值，并且其输出值在z=0附近变化很陡。

其对应的模型称为逻辑斯蒂回归。需要特别说明的是，虽然它的名字是 **回归**，但实际上却是一种分类学习方法。

逻辑斯蒂回归由很多优点：

1. 可以直接对分类可能性进行预测，将y视为样本x作为正例的概率；
2. 无需事先假设数据分布，这样就避免了假设分布不准确所带来的问题
3. 是任意阶可导的凸函数，可直接应用现有数值优化算法求取最优解。

![image-20230719112718317](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719112718317.png)

![image-20230719112729331](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719112729331.png)

逻辑斯蒂回归只能求解连续属性值问题，不能求解离散属性值问题，对于离散属性值的处理：

1. 若属性值之间存在“序”关系：通过连续化将其转化为连续值。
2. 若属性值之间不存在“序”关系：通常可将k个属性值转换为k维向量

## 四、多分类学习

前面讲到的都是二分类学习任务，显示应用中常常会遇到多酚类学习任务。

多分类学习方法

1. 二分类学习方法推广到多类
2. **利用二分类学习器解决多分类问题（常用）**
   - 对问题进行拆分，为拆分出的每个二分类任务训练一个分类器
   - 对每个分类器的预测结果进行集成以获得最终的多分类结果
3. 拆分策略
   - 一对一
   - 一对其余
   - 多对多

一对一拆分：

拆分阶段

1. N个类别两两配对

   N(N-1)/2个二类任务

2. 各个二类任务学习分类器

   N(N-1)/2个二类分类器

测试阶段

1. 新样本提交给所有分类器预测

   N(N-1)/2个分类结果

2. 投票产生最终分类结果

   被预测最多的类别为最终类别

一对其余拆分：

拆分阶段

1. 某一类作为正例，其余类作为反例

   N个二类任务

2. 某个二类任务学习分类器

   N个二类分类器

测试阶段

1. 新样本提交给所有分类器预测

   N个分类结果

2. 比较各分类器的预测置信度

   仅有一个分类器预测为正类，则对应的类别标记作为最终分类结果；若有多个分类器预测为正类，选择置信度最大类别作为最终类别。

![image-20230719142553855](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719142553855.png)

一对一

- 训练N(N-1)/2个分类器。存储开销和测试时间大。
- 训练只用两个类的样例，训练时间短。

一对其余

- 训练N个分类器，存储开销和测试时间小
- 训练用到全部训练样例，训练时间长

预测性能取决于具体数据分布，多数情况下两者差不多。

多对多

- 若干类作为正类，若干个其他类作为反类
- 纠错输出码

![image-20230719142919250](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719142919250.png)

纠错输出码：二元码和三元码

![image-20230719142955756](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719142955756.png)

对分类器错误有一定容忍和修正能力，编码越长、纠错能力越强

对同等长度的编码，理论上来说，任意两个类别之间的编码距离越远，则纠错能力越强

# 第四章：支持向量机学习

## 一、最大边缘超平面

支持向量机（Support Vector Machine，SVM）不仅具有坚实的统计学理论基础，还可以很好的应用与高维数据、避免维度灾难问题，已经成为一种备受关注的机器学习分类技术。

为了解释SVM的基本思想，我们首先介绍一下最大边缘超平面（Maximal Margin Hyperplane）。

给定训练数据集，线性分类器最基本的想法是：在样本空间中寻找一个超平面，将不同类别的样本分开。

给定训练数据集，线性分类器最基本的想法是：在样本空间中寻找一个超平面，将不同类别的样本分开。

![image-20230719143537697](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719143537697.png)![image-20230719143546303](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719143546303.png)

其实能将训练样本分开的超平面可能由很多，分类器必须从这些超平面中选择哪个来表示它的决策边界？

![image-20230719143743824](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719143743824.png)

为了更好地解释不同地超平面对泛化误差地影响，考虑两个超平面B1和B2。

每个超平面bi都对应着一对平行地超平面：bi1和bi2，它们之间的间隔称为超平面的边缘（margin）。

![image-20230719143959004](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719143959004.png)

图中，超平面B1的边缘明显大于B2的边缘。因此，在这个例子中，B1就是训练样本的最大边缘超平面。

## 二、线性支持向量机

直觉上，决策边界的边缘较小，决策边界任何轻微的扰动都可能对分类结果产生较大的影响。也就是说，具有较大边缘的决策边界比那些具有较小边缘的决策边界具有更好的泛化误差。

因此，根据结构风险最小化原理，需要设计最大化决策边界的边缘的线性分类器，以确保最坏情况下的泛化误差最小。线性支持向量机（linear SVM）就是这样的分类器。

![image-20230719145018396](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719145018396.png)

距离决策边界最近的训练样本点使得上式中的等号成立，因此被称为 **支持向量**（support vector）。

两个异类支持向量到决策边界的距离之和被称为决策边界的 **边缘**（margin），刚好等于超平面bi1和bi2之间的间隔y。

为了计算边缘y，令x1是bi1上的一个样本点，x2是bi2上的一个样本点，将x1和x2分别代入上式，得到![image-20230719151634525](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719151634525.png)

令两式相减得到：![image-20230719151703401](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719151703401.png)即![image-20230719151712079](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719151712079.png)

向量![image-20230719151726092](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719151726092.png)在w上的投影乘以w的模：![image-20230719151752055](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719151752055.png)即：![image-20230719151811773](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719151811773.png)

![image-20230719151823429](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719151823429.png)

因此，线性支持向量机的学习就是要寻找满足约束条件的参数w和b，使得y最大，即：

![image-20230719152114973](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719152114973.png)

由于目标函数是二次的，并且约束条件在参数w和b上是线性的，因此线性支持向量机的学习问题是一个凸二次优化问题，可以直接用线程的优化计算包求解，或者用更高效的拉格朗日乘子法求解。

![image-20230719152248115](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719152248115.png)

因为对偶优化问题的二次项前面有个负号，而原始线性支持向量机学习的优化问题的二次项前面没有负号，这说明原来要有缘的最小化问题已经转化成了最大化对偶优化问题。即：

![image-20230719152405747](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719152405747.png)

不过，如果再对上述最大问题稍作变形，就可等价为下面的最小化问题：

![image-20230719152443242](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719152443242.png)

再结合拉格朗日函数的约束条件，就可以得到原始问题的最终优化问题：

![image-20230719152522852](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719152522852.png)

![image-20230719152533822](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719152533822.png)

![image-20230719152552431](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719152552431.png)

## 三、非线性支持向量机

线性SVM假定训练样本是线性可分的，即存在一个线性的决策边界能将所有的训练样本正确分类。

然而在实际应用中，在原始的样本空间内也许并不存在这样的决策边界，

对于这样的我呢提，可以将样本从原始空间映射到一个更高维的特征空间，使得样本在映射后的特征空间内线性可分。例如在下图中，如果将原始的二维空间映射到一个合适的三维空间，就能找到一个合适的划分超平面。幸运的是，如果原始空间是有限维，即属性数目有限，那么一定存在一个更高维的特征空间使得样本线性可分。

![image-20230719153037208](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719153037208.png)

![image-20230719153100247](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719153100247.png)

![image-20230719153111517](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719153111517.png)

那么合适的核函数是否一定存在呢？什么样的函数才能做核函数呢？

根据Mercer定理，只要一个对称函数所对应的核矩阵半定，那么它就能作为核函数来使用。

常用的核函数包括：

![image-20230719153255922](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719153255922.png)

于是，核函数的选择成为非线性SVM的最大变数，若核函数选择不合适，就意味着将样本映射到了一个不合适的特征空间，从而很可能导致非线性SVM性能不佳。

# 第五章：神经网络学习

## 一、神经网络的定义

**神经网络**是由具有适应性的简单单元组成的广泛并行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的反应。

机器学习中的神经网络通常是指 **神经网络学习** ，或者说是机器学习与神经网络两个学科的交叉部分。

既然神经网络的研究是由试图模拟生物神经系统受启发而来的。因此，有必要先来看看生物神经系统的工作过程。

生物神经系统：每个神经元通过轴突与其他相邻的神经元相连，当神经元受到刺激而 **兴奋** 时，就会乡相连的神经元传递神经脉冲，从而改变这些神经元内的电位；如果神经元的电位超过一个 **阈值** ，那么它就会被激活，即 **兴奋** 起来，再向其他相连的神经元传递神经脉冲。

![image-20230719154246332](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719154246332.png)

## 二、神经网络的发展历史

![image-20230719154322342](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719154322342.png)

![image-20230719154332929](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719154332929.png)

![image-20230719154345812](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719154345812.png)

![image-20230719154359792](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719154359792.png)

![image-20230719154410635](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719154410635.png)

![image-20230719154422748](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719154422748.png)

![image-20230719154439936](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719154439936.png)

![image-20230719154454891](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719154454891.png)

## 三、M-P神经元模型

最基本的信息处理单元：M-P神经元模型

**输入**：来自其他m个神经元传递过来的输入信号。

**处理**：输入信号通过带权重的连接进行传递，神经元接受到总输入值将与神经元的阈值进行比较。

**输出**：通过激活函数的处理以得到输出。

![image-20230719154737878](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719154737878.png)

激活函数（Activation Function）：对神经元所获得的网络输入进行变换，也成为激励函数、活化函数：o-f(net)。常用的激活函数有：

1. **线性函数（Linear Function）**
   $$
   f(net)=k*net+c
   $$
   线性函数只能进行线性变化，不适合用来处理非线性问题。

   ![image-20230719155017870](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719155017870.png)

2. **非线性斜面函数（Ramp Function）**

![image-20230719155056006](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719155056006.png)

3. **阈值函数（Threshold Function）**

![image-20230719155136009](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719155136009.png)

4. **逻辑斯蒂函数（Logistic Function）**

![image-20230719155213237](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719155213237.png)

![image-20230719155226629](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719155226629.png)

## 四、单层感知机

### 4.1 单层感知机的定义

单层感知机只拥有一层M-P神经元，即只包含输入层核输出层，输入层接受外界输入信号后传递给输出层，输出层是M-P神经元，进行激活处理。

比如，下面所示的M-P神经元模型，就是一个最简单的单层感知机，输出层只有一个神经元。

![image-20230719155502282](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719155502282.png)

单层感知机的学习规则：

给定训练数据集，单层感知机的权重![image-20230719155538663](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719155538663.png)与阈值theata可以很容易通过学习得到。

在单层感知机中，神经元的阈值theata可看作一个固定输入为-1的”哑节点“所对应的连接权重![image-20230719155700776](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719155700776.png)，这样，权重和阈值的学习就统一为权值的学习了。

对训练样例（x，y），若当前感知机的输出为![image-20230719155805571](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719155805571.png)，则感知机权重调整规则为：![image-20230719155832546](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719155832546.png)其中![image-20230719155847484](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719155847484.png)为学习率。若感知机对训练样例（x，y)预测正确，则感知机不发生变化；否则根据错误程度进行权重的调整。

### 4.2 单层感知机的学习能力

尽管单层感知机能够非常容易地实现逻辑与、或、非运算，但其学习能力还是非常有限。

事实上，逻辑与、或、非运算问题都是线性可分的问题。可以证明，若二分类问题是线性可分的，即存在一个线性超平面能将它们分开，则感知机的学习过程一定会收敛，否则感知机的学习过程将会发生振荡，甚至不能解决异或这样简单的非线性可分问题。

要解决非线性可分问题，就需要使用多层功能神经元。比如两层感知机，输入层与输出层之间的一层神经元，被称为隐含层，隐含层和输出层神经元都是拥有激活函数的功能神经元。

## 五、多层前馈神经网络

### 5.1 多层前馈神经网络的定义

多层前馈神经网络又名多层前馈全互连接网。

**多层是指：**出来输入层和输出层以外，还存在一个或者多个隐含层。

**前馈是指：**外界信号从输入层，经由隐含层达到输出层，不存在信号的逆向传播。

**全互连接是指：**每层神经元与下层神经元全互连接，神经元之间不存在同层连接，也不存在跨层连接。

![image-20230719193537326](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230719193537326.png)

其中输入层神经元接收外界输入，隐含层与输出层神经元对信号进行加工，最终结果由输出层神经元输出。也就是说，输入层神经元只是接受输入，不进行函数处理，隐含层与输出层才进行函数处理。

神经网络参数学习就是根据训练数据来调整神经元之间的连接权以及每个神经元的阈值。换言之，神经网络学到的东西都存放在连接权与阈值中。

### 5.2 多层前馈神经网络的学习

多层前馈神经网络的表达能力比单层感知机要强得多。要学习多层前馈神经网络，单层感知机的学习规则是远远不够的，需要更强大的学习算法。误差逆传播（Error Back Propagation，简称BP）算法就是其中最杰出的代表，它是迄今为止最成功的神经网络学习算法。

显示任务中使用神经网络时，大多是在使用BP算法进行训练。需要指出的是，BP算法不仅可用于前馈神经网络，还可以用于其他神经网络，比如递归神经网络。但通常说BP网络的时候一般是指用BP算法训练的多层前馈神经网络。

![image-20230720092156365](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720092156365.png)

**BP算法的基本过程**

BP算法的基本工作过程大致可以分为三个阶段：

1. 信号的前向传播阶段：在这个阶段，要求计算出隐含层和输出层中每一神经元的网络净输入和网络输出。
2. 误差的逆向传播阶段：在这个阶段，要求计算出输出层和隐含层中每一神经元的误差。
3. 权值和阈值的更新阶段：在这个阶段，要求更新所有连接权的权值和所有M-P神经元的阈值。

**BP算法可能面临的问题**

1. **结构学习问题**

   多层前馈神经网络包括：输入层、输出层、一个或多个隐含层。输入层神经元的个数由输入的数据维度（连续属性）和编码方法（离散属性）确定；输出层神经元的个数由待分类的类别数目和编码方式确定，比如4类问题的二进制编码需要2个神经元。

   证明：只需要一个包含足够多的神经元的隐含层，多层前馈神经网络就能以任意精度逼近任意复杂度的连续函数。

   如何确定隐含层神经元的个数任然是一个悬而未决的问题，实际应用中通常是根据经验来确定或者靠”试错法“来调整。

2. **初始化问题**

   在BP算法中，连接全和偏置在网络学习之前，都需要将其初始化为不同的小随机数。”不同“保证网络可以学习；”小随机数“可以防止其值过大而提前进入饱和状态，达到局部极小值。

   解决办法：重新初始化。

3. **步长设置问题**

   BP网络的收敛是基于无穷小的修改量，学习率控制着算法每一轮迭代中的更新步长。

   步长太小，收敛速度就会过慢

   步长太大，有可能会导致网络的不稳定、甚至瘫痪

   自适应步长，让步长随着网络的训练而不断变化

4. **权值与阈值的更新问题**

   基本的BP算法采用的是样例更新，即每处理一个训练样例就更新一次权值与阈值。样例更新的缺陷：参数更新频繁，不同样例可能抵消，需要迭代的次数较多。另外，训练样例的输入顺序对训练结果有较大影响，它更”偏爱“较后输入的样例。而给训练样例安排一个适当的顺序又是非常困难的。

   解决的办法就是采用周期更新，即每处理一遍所有的训练样例才更新一次权值与阈值。但在很多实际任务中，周期更新的累计误差下降到一定程度后，进一步下降会非常缓慢，这时样例更新往往会获得较好的解，尤其当训练集非常大时效果更明显。

5. **过拟合问题**

   神经网络由于强大的表示能力，经常遭遇过拟合。具体表现为：训练误差持续降低，但测试误差却可能上升。

   缓解过拟合的策略包括早停和正则化。早停就是在训练过程中，若训练误差降低，但验证误差升高，则停止训练；正则化就是在误差目标函数中增加一项描述网络复杂程度的部分，比如连接权值与阈值的平方和。

## 六、深层神经网络的定义

随着云计算、大数据时代的到来，计算能力的答复提高可以缓解训练低效性，训练数据的大幅度增加则可以降低过拟合风险，因此，以深度学习为代表的复杂模型开始受到人们的关注。

典型的深度学习模型就是很深层的神经网络，包含2个以上隐含层的神经网络。

![image-20230720094359273](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720094359273.png)

**模型复杂度**

增加隐含层神经元的数目（模型宽度）

增加隐含层的数目（模型深度）

从增加模型复杂度的角度来看，增加隐藏层的数目比增加隐含层神经元的数目更加有效。这是因为增加隐含层的数目不仅增加了拥有激活函数的神经元数目，还增加了激活函数嵌套的层数。

**深层模型的难点问题**

多隐含层网络难以直接用经典算法（例如标准的BP算法）进行训练，因为误差在多隐含层内逆传播时，往往会发散，而不能收敛到稳定状态。

**预训练+微调**

**预训练：**无监督逐层训练时多隐含层网络训练的有效训练手段，每次训练一层隐含层节点，训练时将上一层隐含层结点的输出作为输入，而本层隐含层结点的输出作为下一层隐含层结点的输入，这称为“预训练”

**微调：**预训练全部完成后，再对整个网络进行微调训练。微调一般使用BP算法。

**例子：**深度信念网络（DBN）

**结构**：每一层都是一个受限Boltzmann机。

**训练：**无监督预训练+BP算法微调。

**分析：**预训练+微调的做法可以视为将大量参数进行分组，对每组先找到局部看起来比较好的设置，然后再基于这些局部较优的结果联合起来进行全局寻优。

**权共享**

一组神经元共享相同的连接权值

例子：卷积神经网络（CNN）

结构：CNN符合多个卷积层和采样层对输入信号进行加工，然后在连接层实现与输出目标之间的映射

训练：BP算法

分析：在训练中，无论是卷积层还是采样层，其每一组神经元（即图下中的每一个平面）都共享相同的连接权，从而大幅减少了需要训练的参数数目；另外，在CNN中通常将Sigmoid

激活函数替换成修正的线性函数：![image-20230720101444121](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720101444121.png)

![image-20230720101504950](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720101504950.png)

卷积层：每个卷积层包含多个特征映射，每个特征映射是一个由多个神经元构成的“平面”，通过一种卷积滤波器提取输入的一种特征。

采样层：也叫“汇合层”，其作用时基于局部相关性原理进行亚采样，从而在减少数据量的同时保留有用的信息。

连接层：每个神经元被全互连接到上一层每个神经元，本质就是传统的神经网路。其目的时通过连接层和输出层的连接完成识别任务。

深度学习通过多层处理，逐渐将初始的低层特征表示转化为高层特征表示后，用“简单模型”即可完成复杂的分类学习等任务。由此可将深度学习理解为进行“特征学习”或“表示学习”。

非深度学习技术用于解决现实任务时，描述样本的特征通常需要由人类专家来手工设计，这称为“特征工程”。众所周知，特征的好坏对模型的泛化性能有至关重要的影响，要人类专家手工设计出好特征并非易事；而特征学习则通过蛇毒学习技术自动产生好特征，这使得机器学习向“全自动数据分析”又前进了一步。

# 第六章：决策树学习

## 一、决策树学习基础知识

决策树学习（decision tree learning）是机器学习中一类最常见的方法之一。顾名思义，决策树学习就是学习用来作决策的树。

决策树学习是一种逼近离散值目标函数的方法，学习到的函数被表示为一棵决策树。

一棵决策树一般包含一个根节点、若干个内部结点和若干个叶子结点。

叶子结点对应于决策结果；

每个内部结点对应于一个属性测试，每个内部结点包含的样本集合根据属性测试的结果被划分到它的儿子结点中；

根节点包含全部训练样本。

从根节点到每个叶子结点的路径对应了一条决策规则。

## 二、决策树学习基本算法

决策树学习的目的就是为了构造一棵泛化能力强，即处理待测样本能力强的决策树，基本算法遵循自顶向下、分而治之的策略，具体步骤如下：

1. 选择最好的属性作为测试属性并创建树的根节点
2. 为测试属性每个可能的取值产生一个分支
3. 训练样本划分到适当的分支形成儿子结点
4. 对每个儿子结点，重复上面的过程，知道所有的结点都是叶子节点

## 三、决策树学习常见问题

可见，决策树的学习是一个递归的过程，过程的实现还需要解决以下六个方面的问题：

1. 最佳划分的度量问题

   从决策树学习基本算法的步骤可以看出，决策树学习的关键是如何选择最佳划分属性，一般而言，随着长树过程的不断进行，我怕们希望决策树的分支节点所包含的样本越来越归属于同一类别。即结点的“不纯度”（impurity）越来越低。

   因此，为了确定按某个属性划分的效果，我们需要比较划分前（父亲结点）和划分后（所有儿子节点）不纯度的降低程度，降低越多，划分的效果就越好。

   若记不纯度的降低程度为▲，则用来确定划分效果的度量标准可以下面的公式来定义：

   ![image-20230720105644636](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720105644636.png)

   其中，I(parent)是父亲节点的不纯度度量，k是划分属性取值的个数。N是父亲结点上样本的总数，N(j)是第j个儿子结点上样本的数目，I(j)是第j个儿子结点的不纯度度量。

   ![image-20230720105832106](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720105832106.png)

   ![image-20230720105847196](C:\Users\79355\Desktop\image-20230720105847196.png)

   ![image-20230720105904709](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720105904709.png)

   ![image-20230720105916232](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720105916232.png)

   ![image-20230720105930398](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720105930398.png)

   ![image-20230720105944084](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720105944084.png)

   ![image-20230720110000877](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720110000877.png)

   ![image-20230720110011210](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720110011210.png)

   ![image-20230720110022597](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720110022597.png)

   ![image-20230720110035205](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720110035205.png)

   ![image-20230720110049595](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720110049595.png)

   ![image-20230720110128344](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720110128344.png)

   ![image-20230720110137854](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720110137854.png)

   ![image-20230720110153744](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720110153744.png)

   ![image-20230720110212416](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720110212416.png)

   ![image-20230720110221549](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230720110221549.png)

2. 处理缺失属性值问题

   显示任务中常会遇到不完整样本，即样本的某些属性值缺失，尤其是在属性数目较多的情况下，往往会有大量样本出现缺失值，面对确实属性值，决策树学习会面临两个方面的问题：

   如何计算含缺失值属性的划分度量、并进行最佳划分的选择？

   选择好最佳划分后，若样本在该属性上的值缺失，如何对样本进行划分？

   处理缺失属性值的问题，通常有两个办法，放弃函缺失值的样本，仅使用无缺失值的样本来进行学习，这种方法杂牌成立数据信息的浪费。

   根据此属性值已知的其他样本，来估计这个缺失的属性值。

   赋给它当前结点所有样本中该属性最常见的值

   赋给它当前结点同类样本中该属性最常见的值

   为含缺失值属性的每个可能值赋予一个概率，而不是简单地将最常见地值赋给它

3. 处理连续属性值问题

   到目前为止我们仅讨论了基于离散属性来生成决策树。显示学习任务中常会遇到连续属性，有必要讨论如何在决策树学习中使用连续属性。

   由于连续属性地可取数目不再有限，因此，不能直接根据连续属性地可取值来对结点进行划分。此时，连续属性的离散化技术可排上用场。

   数据离散化是一个很大的研究主题，学者们提出的离散化技术也很多。可以分为：无监督离散化和有监督离散化。

   无监督离散化常用的有等身分箱法和等宽分箱法：等深分箱法让每个分箱种的样本数目一致；等宽分箱法让每个分箱中的取值范围一致。

   等宽分箱法也叫均分法，就是把一个连续取值的区间等分成若干段，每一段赋一个离散值，常用的有ten-binning。

   有监督离散化常用的有二分法（bi-partition），即将连续取值的属性按选定的阈值分割成布尔属性（二值属性）：

   按照某个连续属性A排列训练样本，找出类标记不同的相邻样本。

   计算类标记不同的相邻样本的属性A的取值的中间值，产生一组候选阈值，可以证明产生最大信息增益的阈值一定在这样的边界中。

   计算与每个候选阈值关联的信息增益，选择具有最大信息增益的阈值来离散化连续属性A。

   二分法的扩展时最小描述长度法（Minimum Description length, MDL）。MDL法将连续取值的属性分割成多个区间，而不是单一阈值的两个区间。

4. 叶子结点的判定问题

   上述三个问题的解决都是围绕树要长大的问题来展开的，那到底什么时候才停止树的生长，也就是递归过程什么时候返回，当前结点会被判定为叶子结点？

   如果我们暂且不考虑树的规模过大而导致的过拟合问题，在决策树学习基本算法中，有三种情形会判定为叶子结点：

   当前结点中的样本集合为空，即空叶子；

   当前结点中的所有样本全部归属于同一类别，即纯叶子；

   当前节点中的所有样本在所有属性上取值相同，即属性被测试完的叶子。

5. 怎样解决过拟合问题

   上述对叶子结点判定的情形，都太过苛刻和完美，从而造成决策树的规模过大，以至于把训练集自身的一些特点当作所有数据都具有的一般性质而导致过拟合问题。

   剪枝（pruning）是解决过拟合问题的主要手段，基本策略有“预剪枝”（prepruning）和“后剪枝”（post pruning）。

   **预剪枝** ：在算法完美划分训练数据集之前就停止树生长。

   **后剪枝** ：允许树过度拟合训练数据，然后对树进行后剪枝。

   尽管预剪枝可能看起来更加直接，但是对过拟合的树进行后剪枝被证明为实践中更成功。这是因为在预剪枝中精确地估计何时停止树增长是非常困难的。

   无论是通过预剪枝还是后剪枝来得到正确规模的树，一个关键问题是使用什么样的准则来确定最终树的规模。

   解决这个问题的方法包括：

   使用与训练样例截然不同的一套分离的样例，来评估通过后剪枝从树上修剪结点的效果。

   使用所有可用数据进行训练，但进行统计测试来估计生长或修剪一个特定的结点是否有可能改善在训练集意外的样例上的性能。

   使用一个明确的标准来衡量训练样例和决策树的复杂度，当这个编码长度最小时停止树的增长。

   上面的第一种方法是最普通的，常被称为训练和验证集法。它将可用数据分成两个样例集合：训练集用于形成学习到的假设；验证集用于评估这个假设在后续数据上的精度。

   训练集和验证机法的动机：及时学习器可能会被训练集误导，但验证集不大可能表现出同样的随机波动。

   通常的做法是，所有样例的三分之二作训练集，三分之一作验证集。

   训练集和验证集法主要包括：错误率降低修剪和规则后修剪。

6. 待测样本的分类问题

   到此，我们解决了决策树生长的相关问题，那么，决策树学到后，怎样应用决策树进行待测样本分类？

   分类待测样本的方法：从决策树的根节点开始，测试这个结点指定的划分属性，然后按照待测样本的该属性值对应的树枝向下移动。这个过程再在以新结点为根的子树上重复，直到将待测样本划分到某个叶子结点为止。然后根据该叶子结点上的训练样本数据集计算其后验概率，最后把具有最大后验概率的类赋给待测样本。

   给定一个叶子结点（其本质是一个训练样本的集合），计算其后验概率的常用方法包括：投票法、加权投票法、局部概率模型法。当计算得到的后验概率出现相同的情况下，可以采用随机分类或者拒判的方法进行处理。

   在计算后验概率的过程中经常会采用一些常用的概率估计方法：基于频率的极大似然估计、拉普拉斯估计、基于相似度（距离）加权的拉普拉斯估计、m-估计，朴素贝叶斯估计等等。

   ![image-20230721161215443](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721161215443.png)

   ![image-20230721161230320](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721161230320.png)

   ![image-20230721161242178](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721161242178.png)

   ![image-20230721161251174](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721161251174.png)

   ![image-20230721161303380](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721161303380.png)

   应用拉普拉斯估计得到待测样本x属于Yes和No的概率分别为：

   ![image-20230721161318851](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721161318851.png)

   决策树学习是以样本为基础的归纳学习方法。它采用自顶向下的递归方式来生长决策树。随着树的生长，完成对训练样本集的不断细分，最终都被细分到了每个叶子结点上。

   决策树的每个结点都是样本的集合，熵等度量刻画了样本度的不纯度，决策树的生长过程是一个熵降低、信息增益、从浑浊到有序的过程。

   决策树学习对噪声数据具有很好的鲁棒性，而且学习得到的决策树还能被表示为多条if-then形式的决策规则，因此具有很强的可读性和可解释性。

# 第七章：贝叶斯学习

## 一、贝叶斯学习基础知识

   用P(h)表示在没有观察到训练数据之前假设h拥有的初始概率，P(h)被称为假设h的先验概率。

   先验概率反应了关于假设h是一正确假设的机会的背景知识；如果没有这一先验知识，可以简单地将每一候选假设赋予相同地先验概率。

   类似地，p(h)表示训练数据D的先验概率，那么P(D|h)就表示假设h成立时D的概率。

   在分类问题中，我们关心的是P(h|D)，即给定D时h的成立的概率，称为h的后验概率。

   交换

   ![image-20230721182349915](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182349915.png)

   ![image-20230721182409720](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182409720.png)

   贝叶斯网络，也叫贝叶斯信念网，是一种用来表示 变量间连续概率的有向无环图模型，图中的节点表 示变量，有向边表示变量间的依赖关系，依赖关系 的强弱用标识在边旁边的条件概率来表示。

   贝叶斯网络表示一组变量的联合概率分布。

   ![image-20230721182527200](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182527200.png)

## 二、贝叶斯最优分类器

   ![image-20230721182550983](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182550983.png)

## 三、朴素贝叶斯分类器

   ![image-20230721182617105](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182617105.png)

   ![image-20230721182643391](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182643391.png)

   ![image-20230721182702107](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182702107.png)

   ![image-20230721182722405](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182722405.png)

## 四、朴素贝叶斯分类器改进

   ![image-20230721182749616](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182749616.png)

   ![image-20230721182808689](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182808689.png)

   ![image-20230721182827263](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182827263.png)

   ![image-20230721182842716](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182842716.png)

   ![image-20230721182854636](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182854636.png)

   ![image-20230721182906138](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182906138.png)

   ![image-20230721182922802](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182922802.png)

   ![image-20230721182945351](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721182945351.png)

   ![image-20230721183005187](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721183005187.png)

   ![image-20230721183018194](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721183018194.png)

   ![image-20230721183036980](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230721183036980.png)

# 第八章：最近邻学习

## 一、最近邻学习基础知识

根据第一章绪论中对分类的定义可知，分类包含两个阶段：训练阶段和工作阶段。

到目前为止，我们前面介绍的所有机器学习技术都有显示的训练过程，都是再训练阶段就对训练样本进行学习处理，构建起分类模型，这类机器学习技术称为“积极学习”（eager learning）。

这一章我们将要介绍的最近邻学习，没有显示的训练过程，在训练阶段只是把训练样本保存起来，建模工作延迟到工作阶段才进行处理，这类机器学习技术称为“消极学习”（

lazy learning）

最近邻学习不是在整个样本空间上一次性的估计目标函数，而是针对每个待测样本作出局部的目标函数逼近。当目标函数很复杂，但它可以用不太复杂的局部函数来逼近时，这样做有非常明显的优势。

最近邻学习可以为不同的待测样本构建起不同的目标函数逼近，因此相比于那些积极的学习技术，最近邻学习往往具有较高的分类性能。

## 二、最近邻学习基础知识

最近邻学习的本思想非常简单：给定待测样本，首先基于某种近邻索引方法找出训练集中与其最靠近的k个样本，然后基于这k个样本的后验概率来预测待测样本的类标记。具体算法分为两个阶段：

训练阶段：

将每个训练样本保存起来。

工作阶段：给定一个待测样本

基于某种近邻索引方法找出训练样本集中与其最靠近的k个样本

基于这k个训练样本的后验概率来预测待测样本的类标记

## 三、最近邻学习常见问题

尽管最近邻学习的基本思想非常简单，但在实际应用中，经常会遇到很多的现实问题：

### 3.1 近邻索引问题

最近邻学习的所有计算几乎都花费在索引近邻问题上。所以如何有效的索引近邻样本，以减少分类时所需计算是一个重要的实践问题。

目前，使用最多的近邻索引方法就是通过计算待测样本与每个训练样本之间的距离，然后基于距离排序，选择距离最短的k个训练样本作为待测样本的最近邻样本。因此如何度量样本点之间的距离就变得非常重要了。

为了度量 样本点之间的距离，学者们提出了许多经典的距离度量函数，根据样本点的数据类型分，主要有：

连续属性：Euclidean距离、Manhattan距离等

离散属性：Overlap Metric距离、Value Difference Metric距离等

混合属性：Heterogeneous Euclidean-Overlap Metric (HEOM)距离、Heterogeneous Value Difference Metric (HVDM)等

简单说，样本点之间的距离总可以分解成样本点在每一维上的差；然后再根据每一维上的数据类型来选择合适的距离函数。

比如HEOM距离就是Euclidean距离和Overlap距离异构而成的 ， HVDM距离就是Euclidean距离和VDM距离异构而成的[Wilson & Martinez, 1997] 。

除了上述基于距离排序的索引方法之外，目前还开发了许多对存储的训练样本进行索引的方法，以便更快速的确定最近邻样本。比如KD-Tree方法把训练样本存储在树的叶子结点上，临近的样本存储在相同或相近的叶子结点上，然后通过测试待测样本在内部结点上的划分属性把待测样本划分到相关的叶子结点上。

这种方法因为树的构建是在训练阶段进行的，所以比基于距离排序的索引方法所需的计算量要小得多。但如何构建有效的树成了另外一个需要解决的问题。

### 3.2 维度灾害问题

前面讲到的许多学习方法，比如决策树学习，只测试部分属性就可以作出判断，而最近邻学习中样本间的距离是根据样本的所有属性来计算的，如果目标函数仅依赖于很多属性中的几个时，样本间的距离会被大量不想关的属性所支配，从而导致相关属性的值很接近的样本相距很远。

这种由于存在很多不想关属性所导致的难题，被称为维度灾难，解决维度灾难问题的常用方法主要包括：1. 属性加权；2. 属性选择。

### 3.3 邻域大小问题

最近邻学习有一个很重要的参数，那就是邻域的大小，即最近邻样本的数目k，最近邻学习的预测结果与k的大小密切相关。同样的数据，k值不同可能导致不同的预测结果。

目前对于k值的选取主要有两种方法：1. 基于经验直接给定；2. 基于数据自动学习。

### 3.4 后验概率问题

给定待测样本的k个最近邻样本，估计其后验概率的常用方法包括：投票法、加权投票法、

局部概率模型法。当计算得到的后验概率出现相同的情况下，可以采取随机分类或者拒接判断的方法进行处理。

在计算后验概率的过程中经常会采用一些常用的概率估计方法：基于频率的极大似然估计、拉普拉斯估计、基于相似度（距离）加权的拉普拉斯估计、m-估计，朴素贝叶斯估计等等。

### 3.5 计算效率问题

最近邻学习推迟所有的计算处理，直到接收到一个新的待测样本，所以分类每个心得待测样本就需要大量的计算。

高效的近邻索引方法可以在一定程度上缓解计算效率问题，比如KD-Tree近邻索引方法。

### 3.6 归纳偏置问题

最近邻学习的归纳偏置是：在输入空间上相近的样本点具有相似的目标函数输出。也就是说，一个待测样本的类标记与它在输入空间中相邻的训练样本的类标记相似。

有效的距离度量方法可以在一定程度上缓解归纳偏置问题，比如属性加权的距离度量方法。

# 第九章：无监督学习

## 一、无监督学习基础知识

提及无监督学习，我们首先会想到聚类。聚类和分类的区别在于训练样本的类标记是未知的。

所谓聚类就是将对物理或抽象对象的集合分组成为由类似的对象组成的多个簇的过程。

聚类生成的组称为簇，簇是数据对象的集合。簇内部的任意两个对象之间具有较好的相似度，而属于不同簇的两个对象之间具有较高的相异度。

相似度和相异度可以根据描述对象的属性值来计算，对象间的距离是最常采用的相异度度量指标。相似度与相异度通常成反比函数关系。

聚类既能作为一个单独的过程，用于找寻数据内在的分布结构，也可作为分类等其他学习任务的前驱过程。

比如，在一些商业应用中需对新用户的类型进行判断，但定义用户类型对商家来说却可能不太容易，此时往往可以对用户数据进行聚类，然后再根据聚类结构将每个簇定义为一个类，最后再基于这些类训练分类模型，用于判断新用户的类型。

基于不同的学习策略，人们设计出多种不同类型的聚类算法，很难对这些聚类算法提出一个简介的分类。大体上，主要的聚类算法可以分为如下五类：

1. 基于划分的方法
2. 基于层次的方法
3. 基于密度的方法
4. 基于网格的方法
5. 基于模型的方法

下面就基于划分的方法做一个简单的介绍。简单说，基于划分的方法就是采用目标函数最小化的策略，通过迭代把数据对象划分为K个组，每个组为一个簇。

基于划分的方法需要满足如下两个条件：

1. 每个分组至少包含一个对象
2. 每个对象属于且仅属于某一个分类

基于划分的方法主要包括K均值（k-means）聚类算法及其变种：K众数（k-modes）、K原型（k-prototypes）、K中心点（k-medoids）、以及K分布（k-distributions）。

## 二、K均值聚类算法

K均值（k-means）

输入：簇的数目K和包含n个对象的数据集D

输出：K个簇的集合。

方法：

1. 从D中任意选择K个对象作为初始簇的质心。
2. 计算每个对象与各簇质心的距离，并将对象划分到距离其最近的簇。
3. 更新每个新簇的质心。
4. 重复执行第2-3步，直到簇中的对象不再变化。

![image-20230724104342369](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724104342369.png)

对K均值聚类算法的几点说明：

只适合于竖直属性数据，当它碰到名词性属性数据的时候，均值可能无定义。

簇的质心就是簇中所有对象再每一位属性上的均值组合而成的虚拟点，并非实际存在的数据点。

对噪声和离群点（孤立点）数据是敏感的，因为它们的存在会对均值的计算产生极大的影响。

对象到质心的距离通常使用欧式距离来计算。

要求用户事先给出要生成簇的数目，即K值要已知。

算法收敛的速度和结果容易受初始质心的影响。

![image-20230724104727299](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724104727299.png)

## 三、K均值聚类算法的变种

**K众数算法（k-modes）**

K均值算法不能聚类名词性属性数据，要聚类名词性属性数据需解决两个问题：

1. 簇质心的计算问题
2. 对象到质心距离的计算问题

对于第一个问题，可以用众数（mode）取替换均值（mean），名词性属性的众数就是具有最高频率的属性值。因此，簇的质心就是簇中所有对象在每一维属性上的众数组合而成的虚拟点。

对于第二个问题，可以用适用于名词性属性的距离函数，比如用OM距离去替换欧式距离。

**K原型算法（k-prototypes）**

如果要聚类的数据既有数值属性又有名词性属性属性，纳闷我们只需把数据对象分类到每一维上，然后根据每一维的属性类型分别进行数值属性和名词性属性处理。

对于第1个问题，簇的质心就是簇中所有对象在每一维属性上的均值或者众数组合而成的虚拟点。

对于第2个问题，可以用适用于混合属性的距离函数，比如，HEOM距离，去替换Euclidean距离。

**K中心点（k-medoids）**

在K均值算法中，簇的质心就是簇中多有对象在每一维属性上的均值组合而成的虚拟点，因此，当数据中存在噪声和离群点（孤立点）时，它们的存在就会对均值的计算产生极大的影响，进而使得计算得到的质心严重脱离了它本该所在的位置。

为了减轻K均值算法对孤立点的敏感性，K中心点算法被提出，K中心点算法不直接采用簇中对象的均值作为簇中心，而选用簇中离均值最近的实际对象作为簇中心。

**K分布（K-distributions）**

前面四种算法不仅需要计算簇的质心，还要计算对象到质心（中心点）的距离。

有没有哪种算法可以避开：

1. 簇质心的计算问题
2. 对象到质心距离的计算问题

这就是K分布算法的设计动机。K分布算法首先将所有对象随即划分成K个非空且互不相交的簇，然后计算每个对象在每个簇上的连个概率分布，并将其分配给具体有最大联合概率分布的簇，一边完成之后，再更新每个新簇包含的对象，此过程重复执行，直到簇的对象不再变化。

输入：簇的数目K；包含n个对象的数据集D

输出：K个簇的集合

方法：

1. 将D随机划分成K个非空且互不相交的簇
2. 计算每个对象再每个簇上的联合概率分布，并将其分配给具有最大概率分布的簇。
3. 更新每个新簇的对象
4. 重复执行第2-3步，直到簇的对象不再变化

![image-20230724110144262](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724110144262.png)

## 四、K均值聚类算法的理解

其实，我们可以从分类的角度来理解K均值聚类算法

首先，我们再来回顾一下K均值算法的步骤

输入：簇的数目K；包含n个对象的数据集D

输出：K个簇的集合

方法：

1. 从D中任意选择K个对象作为初始簇的质心
2. 计算每个对象于各簇质心的距离，并将对象划分到距离其最近的簇
3. 更新每个新簇的质心
4. 重复执行第2-3步，直到簇的质心不再变化

其实，我们可以从分类的角度来理解 K均值聚类算法： 

算法第1步：从D中任意选择K个对象作为初始簇的质心。这相当于是在选择这K个对象作为训练样本，并给训练样本随机分配了类标记。 

算法第2步：计算每个对象与各簇质心的距离，并将对象划分到距离其最近的簇。这相当于是在利用最近邻学习中的1近邻算法分类每一个对象。 

算法第3步：更新每个新簇的质心。这相当于是在更新训练样本。 

算法第4步：重复执行第2-3步，直到簇的质心不再变化。这相当于是在反复迭代利用1近邻算法分类每一个对象，直到分类结果不再发生变化，即算法收敛。

K均值聚类=随机初始标记+有限次迭代收敛的1近邻分类

再推广一下就是： 

虽然聚类是一种无监督学习，给定的已知样本都没有类标记。 但当聚类算法完成随机初始划分之后，每个样本点就相当于都有了类标记，只不过因为初始划分是随机选择的，这些类标记离真实的类标记可能还相差很远。 

一旦样本点有了类标记，我们就可以利用监督学习技术来进行分类学习。因为这些类标记可能还存在错误，利用构建的分类器分类一遍样本是远远不够，还需要然后经过反复迭代分类多遍，不断更新这些类标记。 

既然这样，我们是不是可以得出如下结论： 

聚类=随机初始标记+有限次迭代收敛的分类？ 

如果结论成立，每一个聚类算法是不是都存在一个对应的分类算法？ K均值聚类对应于1近邻分类！K分布呢？其他呢？

# 第十章：集成学习

## 一、集成学习基础知识

集成学习（ensemble learning）通过构建并结合多个学习器来完成学习任务。

有时也被称为多分类器系统、基于委员会的学习等。

集成学习先产生一组”个体学习器“然后再用某种策略将它们结合起来。

集成学习分通知继承和异质集成。通知继承中的个体学习器由相同的学习算法生成，个体学习器称为基学习器；异质集成中的个体学习器由不同的学习算法生成，个体学习器称为组件学习器。

集成学习要显著优于单一个体学习器必须满足两个必要条件：

1. 个体学习器之间应该是相互独立的；
2. 个体学习器应当好于随机猜测学习器。

满足第二个条件往往比较容易，因为再现实任务中，处于种种考虑，比如希望使用较少的个体学习器，或者是希望重用关于常见学习器的一些经验等，人们往往会使用比较强的个体学习器，

满足第一个条件往往比较困难，个体学习器是为了解决同一个问题训练出来的，显然不可能相互独立，事实上，个体学习器的准确性和多样性本身就存在冲突，一般的，准确性很高之后，要增加多样性就需要牺牲准确性。

因此，如何产生好而不同的个体学习器是集成学习研究的核心。

## 二、集成学习常用方法

那么如何再保持个体学习器足够好的前提下增强多样性呢？一般的思路是在学习过程中引入随机性，常用用的方法主要包括：

### 2.1 训练样本扰动

训练样本扰动通常是用抽样的方法从原始训练样本集中产生出不同的样本子集，然后再利用不同的样本子集训练出不同的个体学习器，比如，在装袋Bagging中使用自助采样，在提升Boosting中使用序列采样

此类方法简单高效，使用也最广，但是支队不稳定基学习器有效，比如决策树、神经网络等；对稳定基学习器效果不明显，比如线性学习器、支持向量机、朴素贝叶斯、k-最近邻学习器。

### 2.2 输入属性扰动

输入属性扰动通常是从初始属性集中抽取出若干个属性子集，然后利用不同的属性子集训练出不同的属性子集训练出不同的个体学习器。比如，随机子空间和随机森林。

此类方法对包含大量冗余属性的数据集有效，但若数据集只包含少量属性，或者冗余属性很少，则不宜使用。

### 2.3 输出标记扰动

输出标记扰动通常是对训练样本的类标记稍作变动，比如，可将原来的多分类问题随机转化多个二分类问题来训练基学习器，纠错输出码就是这类方法的典型代表。

此类方法对类数足够多的数据集有效，但若数据集包含的类数较少，则不宜使用。

### 2.4 算法参数扰动

算法参数扰动通常是通过随机设置不同的参数来训练差别较大的个体学习器，比如，神经网络的隐层神经元数、初始链接权值等

此类方法对参数较多的算法有效，对参数较少的算法，可通过将其学习过程中某些缓解用其他类似方式代替，从而达到扰动的目的。

### 2.5 混合扰动

混合扰动是指在同一继承算法中同时使用上述多种扰动方法，比如，随机森林就同时使用了训练样本扰动和输入属性扰动。

## 三、集成学习结合策略

到此为止，我们都是在讨论，怎么通过集成学习的常用方法生成”好而不同“的个体学习器

剩下来要解决的问题：怎么结合生成的个体学习器，具体的结合策略有哪些

对分类任务拉说，最常见的结合策略就是投票法，具体以包括

绝对多数投票法：即若某标记得票过半数，则分类为该标记，否则拒绝分类。 

相对多数投票法：分类为得票最多的标记，若同时有多个标记获最高票，则从中随机选取一个。 

加权投票法：给每个个体学习器预测的类标记赋一 个权值，分类为权值最大的标记。这里的权值通常为该个体学习器的分类置信度（类成员概率）。

# 第十一章：代价敏感学习

## 一、代价敏感学习的背景

常用新能评估指标：准确率或错误率

传统的代价不敏感分类假定：

1. 不同类的误分类代价相同
2. 用于学习的训练数据足够完整

二者在许多实际的应用问题中很难得到满足。原因在于：

1. 不同类的误分类代价经常不同
2. 训练数据也经常因为获取困难、耗时、或者昂贵而不足

作出解决这些实际应用问题的关键技术，代价敏感学习被提出，并受到了机器学习与数据挖掘领域广大学者的高度重视。

## 二、代价敏感学习的定义

代价敏感学习的目标是最小化分类器的总代价，而代价不敏感学习的目标是最小化分类器的错误率。

分类器的代价主要体现在两个方面：

1. 误分类代价
2. 数据获取代价（属性测试代价和类别标注代价）

本课程主要关注误分类代价。误分类代价发生在分类器的预测阶段，主要包括：

1. 类依赖的误分类代价
2. 样本依赖的误分类代价

学习类依赖的误分类代价敏感的分类器要简单使用的多。

类依赖的误分类代价敏感的分类器采用最小化期望代价的原则来进行分类。

分类器将一个猜测样本x分成第i类的期望代价为：

![image-20230724174829572](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724174829572.png)

为了讲解方便，假定待测分类的问题是一个二类分类问题，即只有正负两类，我们用1来表示正类，用0来表示负类，即二类分类问题的误区分类代价矩阵如下：

![image-20230724174944225](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724174944225.png)

## 三、代价敏感学习的评估

给定二类分类问题分类结果的混淆矩阵

![image-20230724175038614](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724175038614.png)

性能评估指标：误分类总代价

![image-20230724175059827](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724175059827.png)

## 四、代价敏感学习的方法

直接代价铭感学习方法直接将分类器的误分类总代价作为学习和优化的目标嵌入分类器的学习过程中，一时的分类器本身具有代价敏感性。

阈值调整的元学习方法通过调整分类器的判断阈值将代价不敏感的分类器转化成代价敏感的分类器。

代价敏感的分类器将一个待测样本x分成第i类，需要最小化期望代价：

![image-20230724175329655](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724175329655.png)

![image-20230724175341671](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724175341671.png)

再平衡的元学习方法通过再平衡训练样本集中不同类的误分总代价将代价不敏感的分类器转化成代价敏感的分类器。

正负两类样本再平衡的缩放比例：

![image-20230724175500751](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724175500751.png)

# 第十二章：演化学习

## 一、演化学习基础知识

定义：演化学习基于演化算法提供的优化工具设计机器学习算法。

![image-20230724175737295](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724175737295.png)

演化算法：或称进化算法，它是一个算法簇，其灵感都来自于大自然的生物进化，演化算法有很多的版本，比如，有不同的遗传基因表达方式，不同的交叉和变异算子，以及不同的再生和选择方法与传统的优化算法相比，演化算法的特点在于：

1. 具有高鲁棒性和广泛适用性；
2. 具有自组织、自适应、自学习的特性
3. 本质并行性
4. 能够不受问题性质的限制，有效处理传统优化算法难以解决的复杂问题

![image-20230724180007483](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724180007483.png)

![image-20230724180103810](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724180103810.png)

## 二、遗传算法

遗传算法是模拟生物再自然环境中的遗传和演化过程而形成的一种自适应全局优化概率搜索算法。

**基本思想**

从初始种群出发，采用优胜劣汰、逝者生存的自然法则选择个体，并通过杂交、变异来产生新一代种群，如此逐代演化，直到满足目标为止。

**特点**

1. 遗传算法是从问题解空间多点并行搜索，而非从单个解开始搜索。
2. 遗传算法利用目标函数的适应度这一信息而非利用导数或其他辅助信息来指导搜索。
3. 遗传算法利用选择、交叉、变异等算子而不是利用确定性规则进行操作。

![image-20230724180521208](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724180521208.png)

![image-20230724180608404](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724180608404.png)

![image-20230724180623962](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724180623962.png)

**适应性度量**

适应度函数是用于对个体的适应性，进行度量的函数。通常，一个个体的适应度值越大，它被遗传到下一代种群中的概率就越大。

**常用的适应度函数**

1. **常用的适应度函数**

   原始适应度函数：直接将待求解问题的目标函数f(x)定义为遗传算法的适应度函数。

   ![image-20230724180839824](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724180839824.png)

   采用原始适应度函数：

   优点：能够直接反映出待求解问题的最初求解目标

   缺点：是有可能出现适应度值为负的情况

2. **标准适应度函数**

   在遗传算法中，一般要求适应度函数值非负，并且，适应度值越大越好，这就往往血药对原始适应度函数进行某种变换，将其转换为标准的度量方式，以满足演化操作的要求，这样所得到的所以硬度函数被称为表混适应度函数fNormal(x)。

   ![image-20230724181145185](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724181145185.png)

**选择操作**

选择操作是指根据选择概率按某种策略从当前种群中挑出一定数目的个体，使得它们能够有更多的机会被遗传到下一代。常用的选择策略：比例选择、排序选择、竞技选择。 

**比例选择：**每个个体被选中的概率与其适应度大小成正 比。比如在轮盘赌选择算法中，个体被选中的概率取决于该 个体的相对适应度。而相对适应度的定义为：

![image-20230724191011816](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724191011816.png)

其中，P(xi)是个体xi的相对适应度，即个体xi被选中的概率；f(xi)是个体xi的原始适应度值；分母是种群的累加适应度值。

轮盘赌选择算法的基本思想是：根据每个个体的选择概率P(xi) 将一个圆盘分成N个扇区，其中第i个扇区的中心角为：

![image-20230724191116360](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724191116360.png)

再设立一个移动指针，选择时，假想转动指针，当指针静止时， 若它指向第i个扇区，则选择个体i。 从统计角度看，个体的适应度值越大，其对应的扇区的面积越大 ，被选中的可能性也越大。

**交叉操作**

交叉操作是指按照某种方式对选择的父代个体的染色体的部分基因进行交叉重组，从而形成新的个体。

交叉重组是自然界中生物遗传进化的一个主要环节，也是遗传算法中产生新的个体最重要的方法之一。根据个体编码方法的不同，遗传算法中的交叉操作可分为二进制交叉和实值交叉两种类型。

二进制交叉是指二进制编码情况下所采用的交叉操作，它主要包括单点交叉、两点交叉和均匀交叉等方法。

**变异操作**

变异是指对选中个体的染色体中的某些基因进行变动，以形成新的个体。变异也是生物遗传和自然演化中的一种基本现象，它可以增强种群的多样性，遗传算法中的变异操作增加了算法的局部随机搜索能力，从而可以维持种群的多样性，根据个体编码方式的不同，变异操作可分为二进制变异和真实值变异两种类型。

**1. 二进制变异**：该变异方法是先随机地产生一个变异位，然后将该变异位置上地基因值由“0”变成“1”，或由“1”变为“0”，产生一个新的个体。例如：设变异前的个体为A=0 0 1 1 0 1，若随机产生的变异位置是2，则该个体的第二位由“0”变成“1”。变异后的新的个体是A`=0 1 1 1 0 1。

**2.实值变异**

![image-20230724192203085](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724192203085.png)

## 三、演化神经网络

**演化神经网络概述**

演化神经网络是基于演化计算和神经网络两大研究方向，将二者有机融合而产生的一种全新神经网络模型。

这种模型把演化计算的自适应机制与神经网络的学习机制有机的结合在一起，有效地克服了传统人工神经网络地很多缺点。

演化神经网络模型地一个主要特点就是它对动态环境地自适应性。这种自适应性过程通过演化地三个等级实现，即连接权值和阈值、网络结构和学习规则地演化。

根据演化神经网路实现地三个等级，演化神经网络有以下四种不同地类型。

![image-20230724192539369](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724192539369.png)

**初始权值阈值演化**

**优化目标**：用遗传算法优化BP神经网络的初始权值和阈值，使得优化后的BP神经网络具有更好的预测精度。

**算法的基本思路**：

1. 对神经网络的初始权值和阈值进行编码
2. 绕都对种群所有个体进行解码，生成多个神经网络
3. 对每个神经网络进行BP训练，然后以均方根误差作为评价标准，对种群中所有个体进行适应度评价。
4. 进行选择、交叉、变异操作，产生新的种群
5. 判断是否达到停止条件，否则转到2运行。

![image-20230724192858427](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724192858427.png)

**初始权值阈值演化----BP神经网络结构**

![image-20230724192924000](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724192924000.png)

![image-20230724193134704](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724193134704.png)

初始权值阈值演化-种群初始化 

设定种群大小为100，每个个体二进制编码长度为5920。 

初始权值阈值演化-适应度值计算 

对每个个体解码，得到592个权值和阈值，每个权值和阈值 的区间为[-0.5,0.5]。 

将权值和阈值赋给BP网络。 

使用训练样本训练BP网络。 

使用回代法计算BP网络的均方根误差。 

适应度函数采用排序的适应度分配函数,对所有网络的均方根误差排序。

![image-20230724193239473](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230724193239473.png)

## 四、演化学习问题与挑战

**存在的问题**：对演化算法这类随机性启发式优化算法而言，其理论研究不足，比如优化效率高低、与最优解的逼近程度如何、启发式算子效用评估等问题难以有严格的答案，这导 致了演化学习也缺乏有效的理论解释。 

**挑战**：近些年，一方面学习模型变得复杂、数据增长迅速、一方面对模型训练时间有严格约束，如何使得演化学习能够 进行有效、快速地优化，还有待深入的研究。

# 第十三章：强化学习

## 一、强化学习概述

**基础概念**： 强化学习又称为增强学习、加强学习、再励学习或激励学习，是一种从环境状态到行为映射的学习，目的是使动作从环境中获得的累计回报值最大。强化学习是机器学习的分支之一，介于监督学习和无监督学习之间。

**机器学习三大分支：**

1. 无监督学习
2. 监督学习
3. 强化学习

![image-20230725121253250](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725121253250.png)

qi昂华学习技术是从控制六年、统计学、心理学等相关学科发展而来。

在人工智能、机器学习和自动控制等领域中得到广泛研究和应用，并被认为是设计只能系统的核心技术之一。

随着强化学习的数学基础研究取得突破性进展后，强化学习成为机器学习领域研究热点之一。

![image-20230725121452908](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725121452908.png)

**强化学习发展历史**

![image-20230725121521435](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725121521435.png)

**强化学习的特点**

强化学习围绕着如何与环境交互学习，在行动-评价的环境中获得改进的行动方案，以适应环境达到预想的目的。学习者并不会被告知采取哪个动作，而只能通过尝试每个动作，获得环境对所采取动作的反馈信息，从而指导以后的行动，因此强化学习的主要特点包括：

![image-20230725121745516](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725121745516.png)

**强化学习基本模型**

在强化学习中，agent选择一个动作a作用域环境；

环境接受该动作后发生变化，同时产生一个强化信号Reward（奖或罚）反馈给Agent；

Agent再根据强化信号和环境的当前状态s再选择下一个动作，选择的原则是使收到奖赏值的概率增大。

强化学习的目的就是寻找一个最优策略，使得Agent在运行中所获得的累计期望回报最大。

![image-20230725122038025](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725122038025.png)

从广义上讲，强化学习是解决序贯决策问题对方法之一，将强化学习纳入马尔科夫决策过程的框架后，可以分为基于模型的动态规划方法和基于无模型的强化学习方法。

## 二、有模型学习

**定义**：在已知模型的环境中学习，成为“有模型学习”，也即，对于多部强化学习任务，其对应的马尔可夫决策过程四元组表示<S,A,R,P>均为已知，称为“模型已知”。

![image-20230725122354343](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725122354343.png)

![image-20230725122402977](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725122402977.png)

**策略迭代算法 - 流程**

1. 某一个随机策略作为初始策略
2. 策略评价+策略改进+策略评价+策略改进+……
3. 若满足收敛条件，则退出，否则，则转入 2

![image-20230725122612707](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725122612707.png)

策略迭代算法的缺点在于：每次改进策略后都需要重新进行策略评价，计算比较耗时。

![image-20230725122634054](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725122634054.png)

![image-20230725122649791](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725122649791.png)

![image-20230725122707526](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725122707526.png)

![image-20230725122717446](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725122717446.png)

![image-20230725122731938](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725122731938.png)

![image-20230725122742074](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725122742074.png)

## 三、无模型学习

当模型未知，即状态转移概率、奖赏函数往往我们是不知道的，甚至很难指导环境中一共有多少状态。此时我们无法直接利用Bellman方程来求解得到最优策略。

若学习算法不依赖环境建模。则称为“无模型学习”，或称为模型无关的学习（model-free Learning）

模型无关的强化学习，是在不知道马尔可夫决策过程的情况下学习到最优策略。模型无关的策略学习主要有两种算法：蒙塔卡罗强化学习、时序差分强化学习。而时序差分强化学习又包括SARSA和Q-learning两种算法。

**蒙特卡洛采样**

MDP是通过5元组：<S,P,A,R,γ>来做决策的。对于这种已知模型的情况，也就是知道了这个5元组，我们额可以通过求解贝尔曼方程获得奖赏最大值。

但是，在现实世界中，我们无法同时知道这个5元组。比如状态转移概率就很难知道，我们无法使用bellman方程来求解V和Q值。

一个想法是，虽然我不知道状态转移概率P，但是这个概率是真实存在的。我们可以直接去尝试，不断采样，然后会得到奖赏，通过奖赏来评价值函数。

**同策略**

![image-20230725123426922](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725123426922.png)

**异策略**

![image-20230725123507049](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725123507049.png)

**时序差分强化学习**

![image-20230725123554683](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725123554683.png)

![image-20230725123859315](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725123859315.png)

时序差分方法：分为同策略的Sarsa和异策略的Q-learning

![image-20230725123920500](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725123920500.png)

![image-20230725123936767](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725123936767.png)

## 四、对强化学习的理解

![image-20230725123946702](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230725123946702.png)

强化学习在某种意义上可看作具有“延迟标记信息”的监督学习问题。

强化学习可以分为基于模型的方法与无模型的方法。前者发展主要来自最优控制领域。而后者发展更多的来自机器学习领域。无模型的强化学习算法通过大量采样，估计智能体的状态--动作值函数或汇报函数，从而获得最优的策略。

但是，无模型的强化学习可能面临的一些问题：

1. 奖励函数难以设计，缺乏理论指导
2. 不对具体问题进行建模，而是尝试用一个通用的算法解决所有问题，没有利用问题固有的信息。
3. 因为没有模型，解释性不强，调试困难。

深度学习（DL）技术和强化学习（RL）的结合，形成了深度强化学习（DRL），迅速成为人工智能届的焦点。

在视频游戏、棋类游戏、机器人控制等领域取得巨大成功。

**可能面临的问题**：

1. 难以平衡“探索”和“利用”，以致算法陷入局部极小。
2. 样本利用较低
3. 对环境容易出现过拟合
4. 灾难性的不稳定

**潜在的研究方向包括**：

1. 提高无模型方法的数据利用率和扩展性
2. 设计高效的探索策略。平衡“探索”与“利用”；
3. 与模仿学习结合，既能更快的得到反馈，又能更快的收敛。
4. 探索好的奖励机制，奖励机制对强化学习的算法性能的影响是巨大的，因此该方向一直是强化学习的研究热点。
5. 混合迁移学习和多任务学习，当前强化的采样效率较低，而且学到的知识不通用，迁移学习与多任务学习可以有效解决这些问题。



# 附1：机器学习模型训练全流程

https://zhuanlan.zhihu.com/p/184673895

https://github.com/dataprofessor/infographic/tree/master

## 1. 数据集

数据集是构建机器学习模型历程中的起点，简单来说，数据集本质上是一个M*N的矩阵，其中M代表列（特征），N代表行（样本）。

列可以分解为X和Y，首先，X是几个类似术语的同义词，如特征、独立变量和输入变量，其次，Y也是几个术语的同义词，即类别标签、因变量和输出变量。

![image-20230802152546578](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230802152546578.png)

图1：数据集的卡通插图

应该注意的是，一个可以用于监督学习的数据集（可以执行回归或分类）将同时包含X和Y，而一个可以用于无监督学习的数据集将只有X。

> 监督学习：X和Y
>
> 无监督学习：X

此外，如果Y包含定量值，那么数据集（由X和Y构成）可以用于回归任务，而如果Y包含定性值，那么数据集（由X和Y构成）可以用于分类任务。

> Y定量：回归
>
> Y定性：分类

## 2. 探索性数据分析（EDA）

进行探索性数据分析（EDA）是为了获得对数据的初步了解，在一个典型的数据科学项目中，我会做的第一件事就是通过EDA来盯住数据，以便更好的了解数据。

我通常使用的三大EDA方法包括：

- 描述性统计：平均数、中位数、模式、标准差
- 数据可视化：热力图（辨别特征内部相关性）、箱型图（可视化群体差异）、散点图（可视化特征之间的相关性）、主成分分析（可视化数据集中呈现的聚类分布）等。
- 数据整形：对数据进行透视、分组、过滤等。

![image-20230802153251177](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230802153251177.png)

图2：NBA球员统计数据的箱型图示例

![image-20230802153328520](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230802153328520.png)

图3：NBA球员统计数据的相关热力图示例

![image-20230802153356921](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230802153356921.png)

图4：NBA球员统计数据的直方图示例

![image-20230802153431286](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230802153431286.png)

图5：NBA球员统计数据的散布图示例

[散布图，怎么做，怎么用](https://zhuanlan.zhihu.com/p/591208271)

[什么是散布图？如何对散布图进行直观观察和分析？](https://www.zhihu.com/question/384245116)

![image-20230802154235741](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230802154235741.png)

## 3. 数据预处理

数据预处理（又称数据清理、数据整理或者数据处理）是对数据进行各种检查和审查的过程，以纠正缺失值、拼写错误、使数值正常化/标准化以使其具有可比性、转换数据（如对数转换）等问题。

> "Garbage in, Garbage out."

正如上言所说，数据的质量将对生成模型的质量产生很大的影响，因此，为了达到最高的模型质量，应该在数据预处理阶段花费大量精力，一般来说，数据预处理可以轻松地占到数据科学项目所划分时间地80%，而实际地模型建立阶段和后续的模型分析仅占到剩余的20%。

## 4. 数据分割

### 4.1 训练-测试集分割

在机器学习模型的开发过程中，希望训练好的模型能在新的，未见过的数据上表现良好，为了模拟新的、未见过的数据，对可用数据进行数据分割，从而将其分割成2部分（有时称为训练-测试分割）。特别是，第一部分是较大的数据子集，用作训练集（如占用原始数据的80%），第二部分通常是较小的子集，用作测试集（其余20%的数据）。需要注意的是，这种数据拆分只进行一次。

接下来，利用训练集建立预测模型，然后将这种训练好的模型应用于测试集（即作为新的、未见过的数据）上进行预测，根据模型在测试集上的表现来选择最佳模型，为了获得最佳模型，还可以进行超参数优化。

![image-20230802161555601](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230802161555601.png)

图6：训练-测试集分割示意图

### 4.2 训练-验证-测试集分割

另一种常见的分割方法是将数据集分割成3部分。（1）训练集，（2）验证集，（3）测试集。与上面解释的类似，训练集用于建立预测模型，同时对验证集进行评估，据此进行预测，可以进行模型调优（如[超参数优化](https://zhuanlan.zhihu.com/p/590823641)），并根据验证集的结果选择性能最好的模型，正如我们所看到的，类似于上面对测试集进行的操作，这里我们在验证集上做同样的操作，请注意，测试集不参与任何模型的建立和准备，因此，测试集可以真正充当新的、未知的数据，Google的《机器学习速成班》对这个话题进行了深入的处理。

![image-20230802193920998](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230802193920998.png)

图7：训练-验证-测试集分割示意图

### 4.3 交叉验证

为了最经济的利用现有数据，通常使用N倍交叉验证（CV），将数据集分割成N个折（通常使用5倍或10倍CV）。在这样的N倍CV中，其中一个折被留作测试数据，而其余的折则被用作建立模型的训练数据。

例如，在5倍CV中，有1个折被省略，作为测试数据，而剩下的4个被集中起来，作为建立模型的训练数据，然后，将训练好的模型应用于上述遗漏的折（即测试数据），这个过程反复进行，直到所有的折都有机会被流出作为测试数据，因此我们将建立5个模型（即5个折中的每个折都被流出来作为测试集），其中5个模型中的每个模型都包含相关的性能指标（我们将在接下来的部分讨论）。最后，度量（指标）值是基于5个模型计算出的平均性能。

![image-20230802194429900](C:\Users\79355\AppData\Roaming\Typora\typora-user-images\image-20230802194429900.png)

图8：交叉验证示意图

在N等于数据样本数的情况下，我们称这种留一的交叉验证，在这种类型的CV中，每个数据样本代表一个折。例如，如果N等于30，那么就有30个折（每个折有1个样本）。在任何其他N折CV中，1个折点被流出作为测试集，而剩下的29个折点被用来建立模型。接下来，将建立的模型应用于对留出的折进行预测，与之前一样，这个过程反复进行，共30次；计算30个模型的平均性能，并将其作为CV性能指标。

## 5. 模型建立

现在有趣的部分来啦，我们终于可以使用精心准备的数据来建立模型了。根据目标变量（通常称为Y变量）的数据类型（定性或定量），我们要建立一个分类（如果Y是定性的）或回归（如果Y是定量）的模型。

### 5.1 学习算法

机器学习算法可以大致分为以下三种类型之一：

- 监督学习：是一种机器学习任务，建立输入X和输出Y变量之间的数学（映射）关系。这样的X、Y对构成了用于建立模型的标签数据，以便学习如何从输入中预测输出。
- 无监督学习：是一种只利用输入X变量的机器学习任务，这种X变量是未标记的数据，学习算法是在建模时使用的是数据的固有结构。
- 强化学习：是一种决定下一步行动方案的机器学习任务，它通过试错学习来实现这一目标，努力使回报最大化。

### 5.2 参数调优

超参数本质上是机器学习算法的参数，直接影响学习过程和预测性能，由于没有”一刀切“的超参数设置，可以普遍适用于所有数据集，因此需要进行超参数优化（也称为超参数调整或模型调整）。

我们以随机森林为例。在使用random Forest R包的时候，通常会对两个常见的超参数进行优化，其中包括mtry和ntree参数（这对应scikit-learnPython库中的RandomForestClassifier()和RandomForestRegressor()函数中的nestimators和maxfeatures）。mtry（maxfeatures）代表在每次分裂时作为候选变量随机采样的变量数量，而ntree（nestimators）代表要生长的树的数量。

另一种流行的机器学习算法是支持向量机。需要优化的超参数是径向基函数（RBF）内核的C参数和gamma参数（即线性内核只有C参数；多项式内核的C和指数）。C参数是一个限制过拟合的惩罚项
